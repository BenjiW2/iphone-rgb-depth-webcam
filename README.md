# iPhone RGB + LiDAR Streaming App

Stream RGB camera and LiDAR depth data from iPhone to computer over network.

## Project Structure

```
iphone_rbg_depth/
â”œâ”€â”€ iphone_rbg_depth/
â”‚   â”œâ”€â”€ ARViewController.swift                 # Main ARKit controller (NEW)
â”‚   â”œâ”€â”€ ARViewControllerRepresentable.swift   # SwiftUI wrapper (NEW)
â”‚   â”œâ”€â”€ ContentView.swift                     # App UI (UPDATED)
â”‚   â”œâ”€â”€ iphone_rbg_depthApp.swift            # App entry point
â”‚   â”œâ”€â”€ Info.plist                           # Permissions (NEW)
â”‚   â””â”€â”€ Assets.xcassets/                     # App assets
â”œâ”€â”€ iphone_rbg_depth.xcodeproj/              # Xcode project
â”œâ”€â”€ PHASE1_SETUP.md                          # Phase 1 instructions
â””â”€â”€ README.md                                # This file
```

## Requirements

- **Device**: iPhone 12 Pro or later (for LiDAR)
- **iOS**: 14.0 or later
- **Xcode**: 13.0 or later
- **macOS**: Big Sur or later (for development)

## Current Status: Phase 1 Complete âœ…

### What's Implemented

- âœ… ARKit session with LiDAR support
- âœ… RGB frame capture
- âœ… Depth frame capture
- âœ… LiDAR availability detection
- âœ… FPS monitoring
- âœ… Status UI overlay
- âœ… Camera & network permissions

### Next: Manual Xcode Setup Required

Before you can run the app, you need to complete a few manual steps in Xcode.

**ðŸ“– See [PHASE1_SETUP.md](PHASE1_SETUP.md) for detailed instructions.**

### Quick Start

1. Open `iphone_rbg_depth.xcodeproj` in Xcode
2. Add the new Swift files to the project (ARViewController.swift, ARViewControllerRepresentable.swift)
3. Configure Info.plist in Build Settings
4. Connect iPhone 12 Pro or later
5. Build and run (Cmd+R)

## Implementation Phases

- [x] **Phase 1**: ARKit setup & LiDAR detection (CURRENT)
- [ ] **Phase 2**: RGB & depth visualization
- [ ] **Phase 3**: Data compression & encoding
- [ ] **Phase 4**: Network streaming
- [ ] **Phase 5**: Receiver application
- [ ] **Phase 6**: Polish & optimization

## Key Features (When Complete)

- Real-time RGB video streaming (H.264)
- Real-time depth map streaming
- Network transmission over WiFi
- Low latency (<100ms target)
- Synchronized RGB + depth frames
- Python/C++ receiver for desktop

## Architecture

```
iPhone (Sender)                    Computer (Receiver)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ARKit         â”‚               â”‚   TCP Server     â”‚
â”‚   â”œâ”€ RGB Camera â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚   â”œâ”€ H.264       â”‚
â”‚   â””â”€ LiDAR      â”‚   Network     â”‚   â””â”€ Depth Data  â”‚
â”‚                 â”‚               â”‚                  â”‚
â”‚   Encoder       â”‚               â”‚   Decoder        â”‚
â”‚   â””â”€ H.264      â”‚               â”‚   â””â”€ OpenCV      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Testing Phase 1

Run the app and verify:

1. **Camera permission** prompt appears
2. **Live AR view** displays
3. **Status shows**: "RGB: 1920x1440, Depth: 256x192"
4. **LiDAR status**: "âœ“ LiDAR Supported" (green)
5. **FPS counter**: Shows 30-60 FPS
6. **Console output**: Frame data logged

## Development Notes

- Built with Swift 5.0+
- Uses ARKit, AVFoundation, Network frameworks
- SwiftUI for UI, UIKit for AR view
- Requires physical device (simulator not supported)

## License

Educational/Personal Project
